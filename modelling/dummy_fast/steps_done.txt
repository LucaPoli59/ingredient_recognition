test done on mexican dataset with input size 224x224 and batch size 128 for 2 epochs
with 10 epochs: 571s
with 2 epochs: 105s

Steps:

- Persistent_workers, Pin_memory, num_workers=2 [75s]
- zero_grad(set_to_none=True) [71s] (dovrebbe già essere di default)
- Chain operations over the forward pass [70s]
- Removing sync operation (effettuato rimuovendo le operazioni di items() e mettendo , to(.., non_blocking=True) [67s]
- Channel Last [65s]
- Mixed precision [64s]





Note:

- Custom accuracy performa meglio di torchmetrics accuracy (nel loop vanilla)
- Custom accuracy e torchmetrics accuracy performano (a batch e size significative) meglio in GPU rispetto a CPU
- Num workers con persistent fanno in modo che la prima epoca sia più lenta, ma le successive più veloci (0.5x), quindi è utile nel training di molte
- Batch size più alta rende il training più veloce ma l'influenza dei workers è minore