import copy
import os
import shutil
import warnings
from typing import Tuple, Type, Optional, List

import lightning as lgn
import numpy as np
import optuna

from src.dashboards.start_optuna import start_optuna

from src.commons.utils import extract_name_trial_dir
from settings.config import (EXPERIMENTS_PATH, DEF_BATCH_SIZE, OPTUNA_JOURNAL_FILENAME, HTUNER_CONFIG_FILE,
                             OPTUNA_JOURNAL_PATH)
from src.training._commons import set_torch_constants, model_training, init_optuna_storage, load_datamodule

from src.data_processing.images_recipes import ImagesRecipesBaseDataModule
from src.lightning.lgn_trainers import TrainerInterface, OptunaTrainer
from src.models.dummy import DummyModel
from src.commons.exp_config import ExpConfig, HGeneratorConfig, HTunerExpConfig


def silence_optuna_warnings():
    warnings.filterwarnings("ignore", "ExperimentalWarning: JournalStorage is experimental "
                                      "(supported from v3.1.0). The interface can change in the future.")

def make_htuning_exp(
        experiment_name: str,
        hgen_config: HGeneratorConfig,
        experiment_dir: str | None = None,
        max_epochs: int = 20,
        batch_size: Optional[int] = DEF_BATCH_SIZE,
        debug: bool = False,
        **config_kwargs
) -> Tuple[lgn.Trainer, lgn.LightningModule]:
    """Function that creates an experiment with hyperparameters tuning with the given configuration and run it.
    If the experiment is resumable, it will resume the last trial.

    Note: Other configuration parameters must be passed as keyword arguments, by following the design pattern
    of the ExpConfig class.
    """
    warnings.filterwarnings("ignore", "Checkpoint directory .*. exists and is not empty.")
    if experiment_dir is None:
        experiment_dir = EXPERIMENTS_PATH

    if not debug:
        optuna.logging.set_verbosity(optuna.logging.ERROR)

    set_torch_constants()

    save_dir, to_resume = _setup_or_resume_dir(experiment_dir, experiment_name)
    if to_resume:
        return _resume_exp(save_dir)

    exp_config = HTunerExpConfig(**config_kwargs)
    _assert_lgn_model_trainer_compatibility(exp_config.lgn_model["lgn_model_type"], exp_config.trainer["type"])
    exp_config.update_config(tr_save_dir=save_dir, tr_debug=debug, tr_max_epochs=max_epochs, batch_size=batch_size,
                             ht_save_dir=os.path.dirname(save_dir))
    return _run_new_exp(exp_config, hgen_config)


def _setup_or_resume_dir(experiment_dir: str | os.PathLike, experiment_name: str | os.PathLike,
                         clear_inconsistent_state: bool = True
                         ) -> Tuple[str | os.PathLike, bool]:
    if not os.path.exists(os.path.join(experiment_dir, experiment_name)):
        os.makedirs(os.path.join(experiment_dir, experiment_name))
        return os.path.join(experiment_dir, experiment_name), False

    if not os.path.exists(OPTUNA_JOURNAL_PATH):
        if clear_inconsistent_state:
            shutil.rmtree(os.path.join(experiment_dir, experiment_name))
            os.makedirs(os.path.join(experiment_dir, experiment_name))
            return os.path.join(experiment_dir, experiment_name), False
        else:
            raise ValueError("Inconsistent state: experiment directory exists but no journal file found.")

    storage = init_optuna_storage()
    studies = optuna.get_all_study_names(storage)
    return os.path.join(experiment_dir, experiment_name), experiment_name in studies


def _restore_study(study_name: str, storage: optuna.storages.BaseStorage,
                   states_error: List[optuna.trial.TrialState], **study_kwargs
                   ) -> Tuple[optuna.study.Study, int]:
    """Function that uses an existing study to create a new one with the valid trials already saved, and the
    invalid ones re-enqueued."""
    old_study = optuna.load_study(study_name=study_name, storage=storage)
    old_trials = old_study.get_trials(deepcopy=True)
    optuna.delete_study(study_name=study_name, storage=storage)

    new_study = optuna.create_study(study_name=study_name, storage=storage, **study_kwargs)
    trials_completed = 0
    for trial in old_trials:
        if trial.state in states_error:
            new_study.enqueue_trial(trial.params)
        else:
            new_study.add_trial(trial)
            trials_completed += 1

    return new_study, trials_completed


def _resume_exp(save_dir: str | os.PathLike) -> Tuple[lgn.Trainer, lgn.LightningModule]:
    """Function that resumes the experiment from the given checkpoint path."""

    exp_config = HTunerExpConfig.load_from_file(os.path.join(save_dir, HTUNER_CONFIG_FILE))
    debug = exp_config.trainer['debug']

    storage = init_optuna_storage()
    exp_dir, exp_name, _ = extract_name_trial_dir(os.path.join(save_dir, "_"))
    study_name = f"{exp_dir}/{exp_name}"

    htuner_config = exp_config.htuner
    sampler = htuner_config["sampler"]()
    pruner = htuner_config["pruner"]()

    study = optuna.load_study(study_name=study_name, storage=storage, sampler=sampler, pruner=pruner)
    if len(study.trials) == 0:
        raise ValueError("No trials found in the study.")

    exp_gen_config = HGeneratorConfig(**study.trials[0].distributions)
    data_module = load_datamodule(exp_config)
    exp_config.drop("lb")

    study, trials_completed = _restore_study(
        study_name, storage, [optuna.trial.TrialState.FAIL, optuna.trial.TrialState.RUNNING],
        sampler=sampler, pruner=pruner)

    if debug:
        print("Resuming Optimization...")

    study.optimize(
        lambda trial: _objective_wrapper(trial, exp_config, data_module, exp_gen_config, check_for_resume=True),
        n_trials=htuner_config["n_trials"] - trials_completed
    )

    return save_best_trial(study, exp_config.trainer["save_dir"], exp_config=exp_config)


def _prepare_trial_dir(trial_path: str | os.PathLike, check_for_resume: bool) -> str | os.PathLike | None:
    if os.path.exists(trial_path) and os.path.exists(os.path.join(trial_path, "checkpoints", "last.ckpt")):
        if check_for_resume:
            return os.path.join(trial_path, "checkpoints", "last.ckpt")
        else:
            shutil.rmtree(trial_path)

    if not os.path.exists(trial_path):
        os.mkdir(trial_path)
    return None


def _assert_lgn_model_trainer_compatibility(model: Type[lgn.LightningModule], trainer: Type[TrainerInterface]):
    """Function that asserts if the model and the trainer are compatible with the training function."""
    if not issubclass(trainer, OptunaTrainer):
        raise ValueError(f"Model must be a subclass of OptunaTrainer, got {model}")


def _run_new_exp(exp_config: HTunerExpConfig, exp_gen_config: HGeneratorConfig
                 ) -> Tuple[lgn.Trainer, lgn.LightningModule]:
    """Function that runs a new experiment with the given configuration."""

    debug = exp_config.trainer['debug']

    # Load the dataset
    data_module = load_datamodule(exp_config)
    exp_config.update_config(dm_label_encoder=data_module.label_encoder.to_config(),
                             tm_num_classes=data_module.get_num_classes())

    # Save the configuration to file
    exp_config.save_to_file(str(os.path.join(exp_config.trainer["save_dir"], HTUNER_CONFIG_FILE)))
    exp_config.drop("lb")  # From this point is useless to carry the label encoder in the config

    htuner_config = exp_config.htuner
    sampler = htuner_config["sampler"]()
    pruner = htuner_config["pruner"]()
    direction = htuner_config["direction"]

    storage = init_optuna_storage()
    exp_dir, exp_name, _ = extract_name_trial_dir(os.path.join(exp_config.trainer["save_dir"], "_"))
    study_name = f"{exp_dir}/{exp_name}"
    study = optuna.create_study(sampler=sampler, direction=direction, study_name=study_name,
                                storage=storage, pruner=pruner)

    if debug:
        print("Starting Optimization...")

    study.optimize(
        lambda trial: _objective_wrapper(trial, exp_config, data_module, exp_gen_config, check_for_resume=False),
        n_trials=htuner_config["n_trials"]
    )

    return save_best_trial(study, exp_config.trainer["save_dir"], exp_config=exp_config)


def save_best_trial(study: optuna.study.Study, save_dir: str | os.PathLike, exp_config: Optional[HTunerExpConfig],
                    ) -> Tuple[TrainerInterface, lgn.LightningModule]:
    best_trial_path_in = os.path.join(save_dir, f"trial_{study.best_trial.number}")
    best_trial_path_out = os.path.join(save_dir, "trial_best")
    shutil.copytree(best_trial_path_in, best_trial_path_out)

    if exp_config is None:
        exp_config = HTunerExpConfig.load_from_file(
            file_path=os.path.join(best_trial_path_out, HTUNER_CONFIG_FILE))  # Questa parte andrÃ  solo dopo il resume

    trainer = exp_config.trainer["type"].load_from_config(exp_config.trainer, trial=study.best_trial)
    model = exp_config.lgn_model["lgn_model_type"].load_from_config(exp_config.lgn_model)

    model = model.load_weights_from_checkpoint(os.path.join(best_trial_path_out, "best_model.ckpt"))
    return trainer, model


def _objective_wrapper(trial: optuna.Trial, exp_config: ExpConfig, data_module: ImagesRecipesBaseDataModule,
                       hparam_gen_config: HGeneratorConfig, check_for_resume: bool = False
                       ) -> float:
    trial_config = copy.deepcopy(exp_config)

    # generate the variable hyperparameters
    hparams = hparam_gen_config.generate_hparams_on_trial(trial)
    variable_hparams_names = [key for key, value in hparam_gen_config.lgn_model.items() if value is not None]

    trial_path = os.path.join(trial_config.trainer["save_dir"], f"trial_{trial.number}")
    resume_path = _prepare_trial_dir(trial_path, check_for_resume)

    # Update the configuration with the generated hyperparameters and the trial
    trial_config.update_config(**hparams, tr_trial=trial, tr_save_dir=trial_path)

    # Run the experiment
    trainer, model = model_training(trial_config, data_module, ckpt_path=resume_path,
                                    lgn_model_kwargs={"hparams_to_register": variable_hparams_names})
    ckpt_callback = trainer.checkpoint_callback
    if ckpt_callback is None:
        raise ValueError("Checkpoint callback not found in the trainer.")
    ris = ckpt_callback.best_model_score

    return ris.item() if ris is not None else np.nan


if __name__ == "__main__":
    silence_optuna_warnings()
    exp_dir, exp_name = os.path.join(EXPERIMENTS_PATH, "dummy_htuning"), "dummy_experiment"
    debug = False
    # random_int = random.randint(0, 100)
    random_int = 69
    exp_name = f"{exp_name}_{random_int}"
    print(exp_name)

    if debug:
        start_optuna()

    hgen_config = HGeneratorConfig(
        hp_lr=(lambda trial: trial.suggest_float("lr", 1e-5, 1e-1, log=True)),
    )

    make_htuning_exp(exp_name, hgen_config, experiment_dir=exp_dir, max_epochs=3, debug=debug,
                     torch_model_type=DummyModel, tr_type=OptunaTrainer, dm_category="mexican", hp_lr=None,
                     tr_limit_train_batches=25, ht_n_trials=3)
