{
 "cells": [
  {
   "cell_type": "code",
   "id": "2bb9b181ee5977",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "#QUESTO VA ESEGUITO USANDO L'ENVIRONMENT \"TEXT_TORCH\" CHE HA PYTORCH, TORCHTEXT (che non è compatibile con la versioen di torchvision) E SPACY"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import torchtext\n",
    "from torchtext import transforms\n",
    "import lightning as lgn\n",
    "\n",
    "from src_scratches.recipes_standardization.seq2seq_model import Encoder, Decoder, Seq2Seq, Seq2SeqDataset, Seq2SeqLightning, Seq2SeqTrainer\n",
    "from settings.config import RECIPES_PATH, METADATA_FILENAME\n",
    "from src_scratches.recipes_standardization.dictionaries import units, quantities_dict, modifiers\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f5a34cae8cad702",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "recipes = json.load(open(os.path.join(RECIPES_PATH, METADATA_FILENAME), 'r'))\n",
    "raw_ingredients = pd.DataFrame(recipes)['ingredients'].explode().unique()\n",
    "raw_ingredients"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a21ad2a951fb9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:24:38.598680Z",
     "start_time": "2024-08-08T10:24:38.584683Z"
    }
   },
   "source": [
    "def synthetic_gen(num_samples):\n",
    "    \n",
    "    x = [0] * num_samples  \n",
    "    y = [0] * num_samples  \n",
    "\n",
    "    for i in range(num_samples):\n",
    "\n",
    "        rnd_qty_str, rnd_qty_int = random.choice(list(quantities_dict.items()))\n",
    "\n",
    "        no_units_present = random.choice([False, False, False, False, True])\n",
    "        rnd_unit = random.choice(units)\n",
    "        \n",
    "        rnd_mod_present = random.choice([None, None, True])\n",
    "        rnd_mod = random.choice(modifiers)\n",
    "\n",
    "        rnd_ing = random.choice(raw_ingredients)\n",
    "\n",
    "        # Build the output string, Y\n",
    "        # e.g. {\"qty\": 36, \"unit\": \"count\", \"item\": \"eggs\", \"mod\": \"scrambled\"}\n",
    "        if no_units_present:\n",
    "            rnd_unit = 'count'  # For purposes of building Y\n",
    "\n",
    "        if rnd_mod_present:\n",
    "            y[i] = f'{{ qty: {rnd_qty_int} , unit: {rnd_unit} , item: {rnd_ing} , mod: {rnd_mod} }}'\n",
    "        else:\n",
    "            y[i] = f'{{ qty: {rnd_qty_int} , unit: {rnd_unit} , item: {rnd_ing} , mod: {None} }}'\n",
    "\n",
    "        # Build the input string, X\n",
    "        # e.g. \"3 dozen scrambled eggs\"\n",
    "        mod_at_end = [False, True]\n",
    "        rnd_mod_at_end = random.choice(mod_at_end)\n",
    "\n",
    "        # avoiding double space\n",
    "        if rnd_mod_present:\n",
    "            if no_units_present:\n",
    "                if rnd_mod_at_end:\n",
    "                    x[i] = f'{rnd_qty_str} {rnd_ing} , {rnd_mod}'             # e.g. 3 eggs, scrambled\n",
    "                else:\n",
    "                    x[i] = f'{rnd_qty_str} {rnd_mod} {rnd_ing}'              # e.g. 3 scrambled eggs\n",
    "            else:\n",
    "                if rnd_mod_at_end:\n",
    "                    x[i] = f'{rnd_qty_str} {rnd_unit} {rnd_ing} , {rnd_mod}'  # e.g. 3 cups eggs, scrambled\n",
    "                else:\n",
    "                    x[i] = f'{rnd_qty_str} {rnd_unit} {rnd_mod} {rnd_ing}'   # e.g. 3 cups scrambled eggs\n",
    "        else:\n",
    "            if no_units_present:\n",
    "                x[i] = f'{rnd_qty_str} {rnd_ing}'                            # e.g. 3 eggs\n",
    "            else:\n",
    "                x[i] = f'{rnd_qty_str} {rnd_unit} {rnd_ing}'                 # e.g. 3 cups eggs\n",
    "\n",
    "    return x, y"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d2e4c9fcc63e1ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:08:48.281948Z",
     "start_time": "2024-08-08T11:08:47.450787Z"
    }
   },
   "source": [
    "N_SAMPLES = 100000\n",
    "TRAIN_SIZE = 0.95 # 95% of the data\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "data = synthetic_gen(N_SAMPLES)\n",
    "data[0][:3], data[1][:3]\n",
    "x, y = data"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:08:49.388444Z",
     "start_time": "2024-08-08T11:08:49.368447Z"
    }
   },
   "cell_type": "code",
   "source": "x[0], y[0]",
   "id": "6fc7f4006b24228a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('seven milliliters infused TACO BELLÂ® Thick & Chunky Medium Salsa',\n",
       " '{ qty: 7 , unit: milliliters , item: TACO BELLÂ® Thick & Chunky Medium Salsa , mod: infused }')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "af2cc44714109464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:08:50.048553Z",
     "start_time": "2024-08-08T11:08:50.038550Z"
    }
   },
   "source": [
    "vocab_size = len(raw_ingredients) + len(modifiers) + len(units) + len(quantities_dict)\n",
    "vocab_size"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7336"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "51dae1323e51e764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:08:50.546103Z",
     "start_time": "2024-08-08T11:08:50.529101Z"
    }
   },
   "source": [
    "def ceil_int(num, target_digit=1):\n",
    "    num_digits = len(str(num))\n",
    "    num = num / 10**(num_digits - target_digit) # e.g. 1234 -> 1.234\n",
    "    return int(np.ceil(num)) * 10**(num_digits - target_digit) # e.g. 1.234 -> 2 * 1000 = 2000\n",
    "\n",
    "vocab_size = ceil_int(vocab_size, 2)\n",
    "vocab_size"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7400"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "3102d172312ffb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:08:51.876034Z",
     "start_time": "2024-08-08T11:08:51.126038Z"
    }
   },
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "def tokenize_en(text, tokenizer=en_nlp, sos_token=sos_token, eos_token=eos_token):\n",
    "    tokenized =  [token.text.lower() for token in tokenizer(text)]\n",
    "    return [sos_token] + tokenized + [eos_token]\n",
    "\n",
    "def tokenize_whitespaces(text, sos_token=sos_token, eos_token=eos_token):\n",
    "    tokenized = text.lower().split()\n",
    "    return [sos_token] + tokenized + [eos_token]\n",
    "tokenize_en(\"3 cups scrambled eggs\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', '3', 'cups', 'scrambled', 'eggs', '<eos>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "edc29d5d32d7c815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:08:54.655994Z",
     "start_time": "2024-08-08T11:08:54.032977Z"
    }
   },
   "source": [
    "\n",
    "min_freq = 1\n",
    "special_tokens = [sos_token, eos_token, unk_token, pad_token]\n",
    "\n",
    "x_tokens = [tokenize_whitespaces(i) for i in tqdm(x)]\n",
    "y_tokens = [tokenize_whitespaces(i) for i in tqdm(y)]\n",
    "\n",
    "train_len = int(len(x_tokens) * TRAIN_SIZE)\n",
    "\n",
    "x_train, y_train = x_tokens[:train_len], y_tokens[:train_len]\n",
    "x_val, y_val = x_tokens[train_len:], y_tokens[train_len:]\n",
    "x_train[:3], y_train[:3]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:00<00:00, 657910.43it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 230417.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['<sos>',\n",
       "   'seven',\n",
       "   'milliliters',\n",
       "   'infused',\n",
       "   'taco',\n",
       "   'bellâ®',\n",
       "   'thick',\n",
       "   '&',\n",
       "   'chunky',\n",
       "   'medium',\n",
       "   'salsa',\n",
       "   '<eos>'],\n",
       "  ['<sos>', '2', 'cup', 'soaked', 'nonfat', 'frozen', 'yogurt', '<eos>'],\n",
       "  ['<sos>',\n",
       "   'two',\n",
       "   'dozen',\n",
       "   't.',\n",
       "   'powdered',\n",
       "   'spice',\n",
       "   'islands',\n",
       "   'garlic',\n",
       "   'salt',\n",
       "   '<eos>']],\n",
       " [['<sos>',\n",
       "   '{',\n",
       "   'qty:',\n",
       "   '7',\n",
       "   ',',\n",
       "   'unit:',\n",
       "   'milliliters',\n",
       "   ',',\n",
       "   'item:',\n",
       "   'taco',\n",
       "   'bellâ®',\n",
       "   'thick',\n",
       "   '&',\n",
       "   'chunky',\n",
       "   'medium',\n",
       "   'salsa',\n",
       "   ',',\n",
       "   'mod:',\n",
       "   'infused',\n",
       "   '}',\n",
       "   '<eos>'],\n",
       "  ['<sos>',\n",
       "   '{',\n",
       "   'qty:',\n",
       "   '2',\n",
       "   ',',\n",
       "   'unit:',\n",
       "   'cup',\n",
       "   ',',\n",
       "   'item:',\n",
       "   'nonfat',\n",
       "   'frozen',\n",
       "   'yogurt',\n",
       "   ',',\n",
       "   'mod:',\n",
       "   'soaked',\n",
       "   '}',\n",
       "   '<eos>'],\n",
       "  ['<sos>',\n",
       "   '{',\n",
       "   'qty:',\n",
       "   '24',\n",
       "   ',',\n",
       "   'unit:',\n",
       "   't.',\n",
       "   ',',\n",
       "   'item:',\n",
       "   'spice',\n",
       "   'islands',\n",
       "   'garlic',\n",
       "   'salt',\n",
       "   ',',\n",
       "   'mod:',\n",
       "   'powdered',\n",
       "   '}',\n",
       "   '<eos>']])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:50:48.981320Z",
     "start_time": "2024-08-08T10:50:48.971319Z"
    }
   },
   "cell_type": "code",
   "source": "tokenize_whitespaces(x[3])",
   "id": "f15de071774768e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', '11', 'milliliters', 'baby', 'artichokes', '<eos>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T11:00:25.821925Z",
     "start_time": "2024-08-08T11:00:25.813924Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = ",
   "id": "8ea0ad9c237334a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', 'cups', 'scrambled', 'eggs']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "f90d58d16f8f0309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:25:56.766996Z",
     "start_time": "2024-08-08T10:25:56.678995Z"
    }
   },
   "source": [
    "x_vocab = torchtext.vocab.build_vocab_from_iterator(x_train, min_freq=min_freq, specials=special_tokens)\n",
    "x_vocab.set_default_index(x_vocab[unk_token])\n",
    "x_vocab.lookup_tokens(x_vocab.lookup_indices(tokenize_en(\"3 cups scrambled eggs\")))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', '3', 'cups', 'scrambled', 'eggs', '<eos>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "eb455477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:25:57.765100Z",
     "start_time": "2024-08-08T10:25:57.672024Z"
    }
   },
   "source": [
    "y_vocab = torchtext.vocab.build_vocab_from_iterator(y_train, min_freq=min_freq, specials=special_tokens)\n",
    "y_vocab.set_default_index(y_vocab[unk_token])\n",
    "y_vocab.lookup_indices(y_train[0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 9, 7, 26, 4, 8, 100, 4, 5, 150, 41, 564, 4, 6, 11, 10, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "766450f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:25:59.112281Z",
     "start_time": "2024-08-08T10:25:59.091284Z"
    }
   },
   "source": [
    "assert x_vocab[pad_token] == y_vocab[pad_token]\n",
    "train_dataset = Seq2SeqDataset(x_train, y_train, x_vocab, y_vocab, pad_token=pad_token)\n",
    "val_dataset = Seq2SeqDataset(x_val, y_val, x_vocab, y_vocab, pad_token=pad_token)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "c005c5e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:26:00.006284Z",
     "start_time": "2024-08-08T10:25:59.989283Z"
    }
   },
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                                pin_memory=True, persistent_workers=True, collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n",
    "                            pin_memory=True, persistent_workers=True, collate_fn=val_dataset.collate_fn)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9322c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(x_vocab)\n",
    "output_dim = len(y_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c965e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d229dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,516,714 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e28143b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 28]) torch.Size([128, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 28, 1130])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "model = model.to(device)\n",
    "# src, trg = next(iter(train_dataloader)), next(iter(train_dataloader))\n",
    "src = next(iter(train_dataloader))[0]\n",
    "trg = src\n",
    "\n",
    "print(src.shape, trg.shape)\n",
    "# torchinfo.summary(model, input_data=(src, trg, 0.5), verbose=2)\n",
    "model(src.to(device), trg.to(device), 0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece8559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "lgn_model = Seq2SeqLightning(\n",
    "    model, lr=0.001, lr_scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    optimizer=torch.optim.SGD, loss_fn=torch.nn.CrossEntropyLoss, batch_size=BATCH_SIZE,\n",
    "    momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "lr_monitor_callback = lgn.pytorch.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "bar_callback = lgn.pytorch.callbacks.RichProgressBar(leave=True)\n",
    "timer_callback = lgn.pytorch.callbacks.Timer()\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')  # For better performance with cuda\n",
    "\n",
    "lgn_trainer = Seq2SeqTrainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    "    log_every_n_steps=len(train_dataloader),\n",
    "    callbacks=[\n",
    "        bar_callback,\n",
    "        timer_callback,\n",
    "        lr_monitor_callback,\n",
    "    ],\n",
    "\n",
    "    accumulate_grad_batches=5,\n",
    "    enable_model_summary=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "062f0286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:574\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    568\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    570\u001B[0m     ckpt_path,\n\u001B[0;32m    571\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    572\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    573\u001B[0m )\n\u001B[1;32m--> 574\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:957\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    956\u001B[0m \u001B[38;5;66;03m# strategy will configure model and move it to the device\u001B[39;00m\n\u001B[1;32m--> 957\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[38;5;66;03m# hook\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:148\u001B[0m, in \u001B[0;36mStrategy.setup\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 148\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\accelerators\\cuda.py:53\u001B[0m, in \u001B[0;36mCUDAAccelerator.setup\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_nvidia_flags(trainer\u001B[38;5;241m.\u001B[39mlocal_rank)\n\u001B[1;32m---> 53\u001B[0m \u001B[43m_clear_cuda_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\fabric\\accelerators\\cuda.py:181\u001B[0m, in \u001B[0;36m_clear_cuda_memory\u001B[1;34m()\u001B[0m\n\u001B[0;32m    180\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_clearCublasWorkspaces()\n\u001B[1;32m--> 181\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\cuda\\memory.py:162\u001B[0m, in \u001B[0;36mempty_cache\u001B[1;34m()\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_initialized():\n\u001B[1;32m--> 162\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_emptyCache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mlgn_trainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlgn_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\programmazione\\python_projects\\ingredient_recognition\\src_scratches\\recipes_standardization\\seq2seq_model.py:194\u001B[0m, in \u001B[0;36mSeq2SeqTrainer.fit\u001B[1;34m(self, model, teacher_forcing_ratio, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, teacher_forcing_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, train_dataloaders\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, val_dataloaders\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, datamodule\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    192\u001B[0m         ckpt_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    193\u001B[0m     model\u001B[38;5;241m.\u001B[39mteacher_forcing_ratio \u001B[38;5;241m=\u001B[39m teacher_forcing_ratio\n\u001B[1;32m--> 194\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:538\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 538\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    540\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:68\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[0;32m     67\u001B[0m     _interrupt(trainer, exception)\n\u001B[1;32m---> 68\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_teardown\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# teardown might access the stage so we reset it after\u001B[39;00m\n\u001B[0;32m     70\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1004\u001B[0m, in \u001B[0;36mTrainer._teardown\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1001\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_teardown\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1002\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001B[39;00m\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1004\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mteardown\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1005\u001B[0m     loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_active_loop\n\u001B[0;32m   1006\u001B[0m     \u001B[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:535\u001B[0m, in \u001B[0;36mStrategy.teardown\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    534\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: moving model to CPU\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 535\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mteardown()\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\lightning\\fabric\\utilities\\device_dtype_mixin.py:82\u001B[0m, in \u001B[0;36m_DeviceDtypeModuleMixin.cpu\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001B[39;00m\n\u001B[0;32m     81\u001B[0m _update_properties(\u001B[38;5;28mself\u001B[39m, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m---> 82\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:960\u001B[0m, in \u001B[0;36mModule.cpu\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcpu\u001B[39m(\u001B[38;5;28mself\u001B[39m: T) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    952\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \n\u001B[0;32m    954\u001B[0m \u001B[38;5;124;03m    .. note::\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    958\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    959\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 960\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    821\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    823\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 825\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    826\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32mc:\\Users\\polil\\.conda\\envs\\text_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:960\u001B[0m, in \u001B[0;36mModule.cpu.<locals>.<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcpu\u001B[39m(\u001B[38;5;28mself\u001B[39m: T) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    952\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \n\u001B[0;32m    954\u001B[0m \u001B[38;5;124;03m    .. note::\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    958\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    959\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 960\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "lgn_trainer.fit(model=lgn_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da270a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
