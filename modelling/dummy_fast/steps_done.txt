test done on mexican dataset with input size 224x224 and batch size 128 for 2 epochs
with 10 epochs: 571s
with 2 epochs: 105s

Steps:

- Persistent_workers, Pin_memory, num_workers=2 [80s]





Note:

- Custom accuracy performa meglio di torchmetrics accuracy (nel loop vanilla)
- Custom accuracy e torchmetrics accuracy performano (a batch e size significative) meglio in GPU rispetto a CPU
- Num workers con persistent fanno in modo che la prima epoca sia più lenta, ma le successive più veloci (0.5x), quindi è utile nel training di molte
- Batch size più alta rende il training più veloce ma l'influenza dei workers è minore