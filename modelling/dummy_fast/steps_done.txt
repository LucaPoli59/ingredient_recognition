test done on mexican dataset with input size 224x224 and batch size 128 for 2 epochs
with 10 epochs:

Steps:

- Prettier Epochs logs [Stesso tempo ~118s]
- Num workers messo a X e pin_memory a True  (nb potrebbe essere legato al batch size)
--- 0 workers: 109s
--- 1 worker: 118s
--- 2 workers: 114s
--- 3 workers: 101s  (98 x2)
--- 4 workers: 115s
--- 8 workers: 120s





Note:

- Custom accuracy performa meglio di torchmetrics accuracy (nel loop vanilla)
- Custom accuracy e torchmetrics accuracy performano (a batch e size significative) meglio in GPU rispetto a CPU
- Num workers con persistent fanno in modo che la prima epoca sia più lenta, ma le successive più veloci (0.5x), quindi è utile nel training di molte